## Introduction

This project utilized a powerful stack of tools and technologies to build a real-time data streaming pipeline, covering each phase from data ingestion to processing and storage.

In this project, I set up a data pipeline with Apache Airflow, streamed with Kafka and Kafka connector, processed with Spark, and stored with Cassandra. 

All the tools were containerized with Docker.

## source

I followed the yutube video an learned how to use these tools.

https://www.youtube.com/watch?v=GqAcTrqKcrY


From this video and other related videos, I learned how to use these powerful tools to build a data pipeline.



